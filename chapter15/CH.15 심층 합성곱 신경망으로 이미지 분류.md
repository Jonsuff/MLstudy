# CH.15 심층 합성곱 신경망으로 이미지 분류

- **합성곱 신경망**(Convolutional Neural Network, CNN)



## 15.1 합성곱 신경망의 구성 요소

CNN은 **뇌의 시각 피질이 물체를 인식할 때 동작하는 방식**에서 영감을 얻은 모델이다(CNN이 뇌와 같은 방법으로 작동한다는 의미는 아니다).

CNN은 이미지 분류 작업에서 탁월한 성능을 내어 주목받은 기술이다.



### 15.1.1 CNN과 특성 계층 학습

이미지를 분류하는데 핵심이 되는 특징을 올바르게 추출하는 것은 모든 머신러닝 알고리즘의 성능에서 중요한 요소이다. 머신러닝에서 특징을 추출해내는 방법은 크게 두가지가 있다.

1. 도메인 전문가가 만든 특성에 의존
2. 컴퓨터를 사용한 특성 추출 기법을 이용

신경망은 원본 데이터에서 작업에 가장 유용한 특성을 자동으로 학습할 수 있기 때문에 신경망을 특성 추출 엔진으로 생각하기도 한다. (ex) 입력에 가까운 층은 저수준 특성을 추출할 수 있다.

고수준 특성을 추출하기 위해서는 다층 신경망을 사용한다.

- 심층 합성곱 신경망 : 

  각 층별로 저수준 특성을 연결하여 고수준 특성을 만듦으로써 특성 계층을 구성.

- 저수준 특성 : 

  에지(edge), 동그라미, 네모 등 도형이나 일정한 패턴의 선

- 고수준 특성 : 

  저수준 특성들이 모여서 건물, 자동차, 강아지 등 의미있는 이미지를 형성한 것.

- 특성 맵(feature map) : 

  입력된 이미지에서 만드는 특성 맵은 전체 이미지에서 작은 일부분을 선택해 그 부분 내에서의 특성을 파악하여 한 픽셀로 표현한 것.

  다음과 같은 이미지로 예를 들 수 있다.

  ![](https://raw.githubusercontent.com/Jonsuff/MLstudy/master/images/ch15_feature_map_fixed.png)

- CNN은 다음과 같은 이유로 이미지 관련 작업을 잘 수행한다.

  - 희소 연결 : 

    특성 맵에 있는 하나의 원소는 작은 픽셀 패치 하나에만 연결된다(퍼셉트론처럼 모든 입력 이미지에 연결되는 것과 매우 다르다).

  - 파라미터 공유 : 

    동일한 가중치가 입력 이미지의 모든 패치에 사용된다.

  이 두 아이디어의 결과로 네트워크의 파라미터 개수가 감소하고 중요한 특징은 더 잘 잡아낸다.

- 일반적으로 CNN은 여러개의 **합성곱 층(convolution)**과 풀링(Pooling) 이라고도 불리는 **서브샘플링 층(subsampling)**으로 이루어져 있다.

  마지막에는 하나 이상의 완전히 연결된(Fully connected) 층이 붙는다. 이 층은 모든 입력이 모든 출력에 가중치가 곱하여 연결되어있는 다층 퍼셉트론이다.

- **풀링 층(=서브샘플링 층)**은 학습되는 파라미터가 없다. 

  $$\Rightarrow$$ 가중치나 절편이 존재하지 않는다.



### 15.1.2 이산 합성곱 수행

CNN의 기본 연산인 합성곱은 **이산 합성곱**(discrete convolution) 방법이다.

- 이산 합성곱의 수학적 정의
  $$
  \mathbf{y} = \mathbf{x} * \mathbf{w} \rarr \mathbf{y[\mathrm{i}]} = \sum^{+\infin}_{k = -\infin} \mathbf{x[\mathrm{i-k}]} \mathbf{w[\mathrm{k}]}
  $$
  [] : 벡터 원소의 인덱스

  i = 출력 벡터 **y**의 각 원소에 대응

  - 합연산에서 k의 범위가 $$+\infin$$ 에서 $$-\infin$$ 까지인것은 바르지 않다. 입력이 유한한 상황에서 k의 범위가 무한대로 뻗어나가면 출력또한 유효한 입력이 아닌 부분이 0으로 채워진 무한한 크기의 벡터가 되기 때문이다. 이를 해결하기 위해 **패딩**(padding) 작업을 해준다.

  

- 

